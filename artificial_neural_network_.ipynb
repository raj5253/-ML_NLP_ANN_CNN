{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lP6JLo1tGNBg"},"source":["# Artificial Neural Network"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gWZyYmS_UE_L"},"source":["### Importing the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as  tf"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["'2.10.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1E0Q3aoKUCRX"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cKWAkFVGUU0Z"},"source":["### Importing the dataset"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["dataset = pd.read_csv('Churn_Modelling.csv')\n","X = dataset.iloc[: ,3:-1].values   #the first 3 rows are not impact on descision.\n","y = dataset.iloc[: , -1].values"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n","[1 0 1 ... 1 1 0]\n"]}],"source":["print(X)\n","print(y)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N6bQ0UgSU-NJ"},"source":["### Encoding categorical data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"le5MJreAbW52"},"source":["Label Encoding the \"Gender\" column"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["# categorical features need tobe  encoded to Numerical (3rd col ->gender)\n","from sklearn.preprocessing import LabelEncoder\n","le  = LabelEncoder()            #labelEncoding -> covert gender(categorical) to male(binary 0: female, 1: male) , and no female column.\n","                                # if female(binary) col present , then it is OneHotEncoding\n","X[:, 2] = le.fit_transform(X[:, 2])\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CUxGZezpbMcb"},"source":["One Hot Encoding the \"Geography\" column"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))\n","\n","# the 3 new columns ,for replace of geography, appear at beging of table"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}],"source":["print(X)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vHol938cW8zd"},"source":["### Splitting the dataset into the Training set and Test set"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test,y_train , y_test = train_test_split(X, y, test_size=0.2,random_state=0)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"RE_FcHyfV3TQ"},"source":["### Feature Scaling"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["# some features have higher numerical values. so scaling of them is required.\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-zfEzkRVXIwF"},"source":["## Part 2 - Building the ANN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KvdeScabXtlB"},"source":["### Initializing the ANN"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["ann = tf.keras.models.Sequential()"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rP6urV6SX7kS"},"source":["### Adding the input layer and the first hidden layer"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))   #add allows to add hidden  layer to ann model\n","# relu = rectifier activation function\n","# unit = 6 means there are 6 input nodes in input layer"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BELWAc_8YJze"},"source":["### Adding the second hidden layer"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OyNEe6RXYcU4"},"source":["### Adding the output layer"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[],"source":["ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) #ouput  is only one variable, so only 1 node\n","\n","# here binaryclassification  need to be used so -> sigmoid\n","# if categorical classification then ->'soft max'"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JT4u2S1_Y4WG"},"source":["## Part 3 - Training the ANN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8GWlJChhY_ZI"},"source":["### Compiling the ANN"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["ann.compile(optimizer= 'adam', loss= 'binary_crossentropy', metrics=  ['accuracy'])"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0QR_G5u7ZLSM"},"source":["### Training the ANN on the Training set"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","250/250 [==============================] - 1s 956us/step - loss: 0.7257 - accuracy: 0.5584\n","Epoch 2/100\n","250/250 [==============================] - 0s 964us/step - loss: 0.5286 - accuracy: 0.7959\n","Epoch 3/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7977\n","Epoch 4/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8139\n","Epoch 5/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4103 - accuracy: 0.8250\n","Epoch 6/100\n","250/250 [==============================] - 0s 996us/step - loss: 0.3944 - accuracy: 0.8342\n","Epoch 7/100\n","250/250 [==============================] - 0s 984us/step - loss: 0.3821 - accuracy: 0.8422\n","Epoch 8/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8460\n","Epoch 9/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8490\n","Epoch 10/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8520\n","Epoch 11/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8521\n","Epoch 12/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.8536\n","Epoch 13/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8555\n","Epoch 14/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8560\n","Epoch 15/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3507 - accuracy: 0.8559\n","Epoch 16/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8571\n","Epoch 17/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8584\n","Epoch 18/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3474 - accuracy: 0.8593\n","Epoch 19/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8593\n","Epoch 20/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8596\n","Epoch 21/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3445 - accuracy: 0.8597\n","Epoch 22/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3435 - accuracy: 0.8612\n","Epoch 23/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8609\n","Epoch 24/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8612\n","Epoch 25/100\n","250/250 [==============================] - 1s 3ms/step - loss: 0.3418 - accuracy: 0.8604\n","Epoch 26/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3414 - accuracy: 0.8626\n","Epoch 27/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8605\n","Epoch 28/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8605\n","Epoch 29/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8621\n","Epoch 30/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8614\n","Epoch 31/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3390 - accuracy: 0.8604\n","Epoch 32/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8618\n","Epoch 33/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8612\n","Epoch 34/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8619\n","Epoch 35/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8625\n","Epoch 36/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8629\n","Epoch 37/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8618\n","Epoch 38/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8626\n","Epoch 39/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3372 - accuracy: 0.8620\n","Epoch 40/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8639\n","Epoch 41/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8626\n","Epoch 42/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8605\n","Epoch 43/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8630\n","Epoch 44/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8614\n","Epoch 45/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8629\n","Epoch 46/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8627\n","Epoch 47/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8624\n","Epoch 48/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8634\n","Epoch 49/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8631\n","Epoch 50/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8649\n","Epoch 51/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8627\n","Epoch 52/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8631\n","Epoch 53/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8634\n","Epoch 54/100\n","250/250 [==============================] - 0s 984us/step - loss: 0.3341 - accuracy: 0.8637\n","Epoch 55/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3333 - accuracy: 0.8636\n","Epoch 56/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8637\n","Epoch 57/100\n","250/250 [==============================] - 1s 2ms/step - loss: 0.3329 - accuracy: 0.8637\n","Epoch 58/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8646\n","Epoch 59/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8639\n","Epoch 60/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8630\n","Epoch 61/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8639\n","Epoch 62/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8634\n","Epoch 63/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8633\n","Epoch 64/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8626\n","Epoch 65/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8650\n","Epoch 66/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8656\n","Epoch 67/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8640\n","Epoch 68/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8643\n","Epoch 69/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8636\n","Epoch 70/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8644\n","Epoch 71/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8650\n","Epoch 72/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8641\n","Epoch 73/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8639\n","Epoch 74/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8644\n","Epoch 75/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8641\n","Epoch 76/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8655\n","Epoch 77/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8649\n","Epoch 78/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8629\n","Epoch 79/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8639\n","Epoch 80/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8648\n","Epoch 81/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8631\n","Epoch 82/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8654\n","Epoch 83/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8651\n","Epoch 84/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8636\n","Epoch 85/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8639\n","Epoch 86/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8658\n","Epoch 87/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8634\n","Epoch 88/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8625\n","Epoch 89/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8655\n","Epoch 90/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8644\n","Epoch 91/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8627\n","Epoch 92/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8649\n","Epoch 93/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8651\n","Epoch 94/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8640\n","Epoch 95/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8643\n","Epoch 96/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8626\n","Epoch 97/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8641\n","Epoch 98/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8635\n","Epoch 99/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8643\n","Epoch 100/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8636\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1c784c40bb0>"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["ann.fit(X_train, y_train , batch_size=32,  epochs= 100)  #epochs helps in error correction\n","\n","#divisions size - 32 .eposch = number of time to  backtrack "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tJj5k2MxZga3"},"source":["## Part 4 - Making the predictions and evaluating the model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"84QFoqGYeXHL"},"source":["### Predicting the result of a single observation"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 17ms/step\n","[[False]]\n"]}],"source":["# input shouldbe 2d array\n","# required features should be encoded and scaled before use\n","# 1, 0, 0 for france\n","\n","\n","print(ann.predict(sc.transform([[ 1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)\n","\n","# ann.predict gives the probality value of (non)leaving the bank by customer"]},{"attachments":{},"cell_type":"markdown","metadata":{"colab_type":"text","id":"CGRo3eacgDdC"},"source":["using ANN model to predict if the customer with the following informations will leave the bank: \n","\n","Geography: France\n","\n","Credit Score: 600\n","\n","Gender: Male\n","\n","Age: 40 years old\n","\n","Tenure: 3 years\n","\n","Balance: \\$ 60000\n","\n","Number of Products: 2\n","\n","Does this customer have a credit card? Yes\n","\n","Is this customer an Active Member: Yes\n","\n","Estimated Salary: \\$ 50000\n","\n","Will the customer leave the bank ?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZhU1LTgPg-kH"},"source":["**Solution**"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":33990,"status":"ok","timestamp":1590257481594,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"2d8IoCCkeWGL","outputId":"957f3970-e197-4c3b-a150-7f69dc567f5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 27ms/step\n","[[False]]\n"]}],"source":["print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u7yx47jPZt11"},"source":["### Predicting the Test set results"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"colab_type":"code","executionInfo":{"elapsed":33987,"status":"ok","timestamp":1590257481595,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"nIyEeQdRZwgs","outputId":"82330ba8-9bdc-4fd1-d3cf-b6d78ee7c2a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["63/63 [==============================] - 0s 893us/step\n","[[0 0]\n"," [0 1]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n"]}],"source":["y_pred = ann.predict(X_test)\n","y_pred = (y_pred > 0.5 )\n","print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"o0oyfLWoaEGw"},"source":["### Making the Confusion Matrix"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"colab_type":"code","executionInfo":{"elapsed":33981,"status":"ok","timestamp":1590257481595,"user":{"displayName":"Hadelin de Ponteves","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhEuXdT7eQweUmRPW8_laJuPggSK6hfvpl5a6WBaA=s64","userId":"15047218817161520419"},"user_tz":-240},"id":"ci6K_r6LaF6P","outputId":"4d854e9e-22d5-432f-f6e5-a102fe3ae0bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1518   77]\n"," [ 208  197]]\n"]},{"data":{"text/plain":["0.8575"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test, y_pred)  # y_true, y_pred\n","print(cm)\n","accuracy_score(y_test, y_pred)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMeRFWFoGrdaL5S3dx5MWmb","collapsed_sections":[],"name":"artificial_neural_network.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
